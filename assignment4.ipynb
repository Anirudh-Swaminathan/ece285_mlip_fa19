{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Image Denoising with Deep CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Anirudh Swaminathan\n",
    "### PID: A53316083\n",
    "### Email ID: aswamina@eng.ucsd.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook created by Anirudh Swaminathan from ECE department majoring in Intelligent Systems, Robotics and Control for the course ECE285 Machine Learning for Image Processing for Fall 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import nntools as nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating noisy images of BSDS dataset with DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_dir = '/datasets/ee285f-public/bsds/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created the $dataset\\_root\\_dir$ and made it point to the BSDS dataset directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyBSDSDataset(td.Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, mode='train', image_size=(180, 180), sigma=30):\n",
    "        super(NoisyBSDSDataset, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.image_size = image_size\n",
    "        self.sigma = sigma\n",
    "        self.images_dir = os.path.join(root_dir, mode)\n",
    "        self.files = os.listdir(self.images_dir)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"NoisyBSDSDataset(mode={}, image_size={}, sigma={})\".format(self.mode, self.image_size, self.sigma)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.images_dir, self.files[idx])\n",
    "        \n",
    "        # Read the original image\n",
    "        clean = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # choose i as random index to start the row crop from\n",
    "        i = np.random.randint(clean.size[0] - self.image_size[0])\n",
    "        \n",
    "        # choose j as the random index to start the column crop from\n",
    "        j = np.random.randint(clean.size[1] - self.image_size[1])\n",
    "        # COMPLETE\n",
    "        # crop the image\n",
    "        clean = clean.crop([i, j, i+self.image_size[0], j+self.image_size[1]])\n",
    "        \n",
    "        # transform and normalize\n",
    "        transform = tv.transforms.Compose([\n",
    "            # convert to torch tensor\n",
    "            tv.transforms.ToTensor(),\n",
    "            \n",
    "            # Normalize each channel from [-1, 1]\n",
    "            tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "        \n",
    "        # apply the transform on the image\n",
    "        clean = transform(clean)\n",
    "        \n",
    "        noisy = clean + 2 / 255 * self.sigma * torch.randn(clean.shape)\n",
    "        return noisy, clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I initially cropped the image to the requried image_size from the random indices that were generated using the $.crop()$ method. <br>\n",
    "Then the image is converted to a torch tensor using the $tv.transforms.ToTensor()$ function. <br>\n",
    "$$\\textbf{NOTE:-} \\text{The }tv.trasforms.ToTensor() \\text{ converts the PIL image from range }(0, 255) \\text{ to a tensor of range }(0, 1)$$\n",
    "Finally, I normalize the image using the $tv.transforms.Normalize()$ function. <br>\n",
    "This function takes means and standard deviations for each channel as the input. Since each channel has been transformed to $(0, 1)$ by the $tv.transforms.ToTensor()$ function, we have the mean for each channel is $0.5$ and the standard deviation is $0.5$. <br>\n",
    "As given in the $PyTorch$ source code and documentation, the $tv.transforms.Normalize()$ function subtracts the mean for each channel from the image, and then divides by the standard deviation, so now the tensor in the range from $(0, 1)$ is converted to $\\left( \\frac{(0-0.5)}{0.5}, \\frac{(1-0.5)}{0.5} \\right)$, which is $(-1, 1)$. <br>\n",
    "Finallly, as given in the question, the noisy image is generated by creating a torch tensor whose elements are individually sampled from the standard normal distribution $\\mathcal{N} \\sim \\left(0, 1\\right)$. <br>\n",
    "This is then multiplied with the $\\sigma$ that we require to convert it to $\\mathcal{N} \\sim \\left(0, \\sigma \\right)$. <br>\n",
    "Finally, the noisy image is normalized using the $\\frac{2}{255}$ to ensure it is in the range of $(-1, 1)$.\n",
    "This is because the $\\sigma$ was for the origial pixel values with range from $0$ to $255$ and so, we divide by $255$. <br>\n",
    "As discussed in Piazza, we then multiply by $2$ as the range of the values are doubled from $(0, 1)$ to $(-1, 1)$. <br>\n",
    "Finally the noisy image is distributed as follows:- \n",
    "$$\\text{noisy image} = \\text{clean image} + \\mathcal{N} \\sim \\left(0, \\frac{2\\sigma}{255}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myimshow(image, ax=plt):\n",
    "    image = image.to('cpu').numpy()\n",
    "    image = np.moveaxis(image, [0, 1, 2], [2, 0, 1])\n",
    "    image = (image + 1) / 2\n",
    "    image[image<0] = 0\n",
    "    image[image>1] = 1\n",
    "    h = ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider training set and the testing set from this class\n",
    "train_set = NoisyBSDSDataset(root_dir=dataset_root_dir)\n",
    "test_set = NoisyBSDSDataset(root_dir=dataset_root_dir, mode=\"test\", image_size=(320, 320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12th index image in the testing set\n",
    "x = test_set.__getitem__(12)\n",
    "noi = x[0]\n",
    "cle = x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(noi), noi.dtype, noi.size(), noi.min(), noi.max())\n",
    "print(type(cle), cle.dtype, cle.size(), cle.min(), cle.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Noisy and Clean image for the 12th index of the testing set\n",
    "fig, axes = plt.subplots(ncols=2)\n",
    "fig.suptitle(\"Noisy and clean image at index 12 of testing set\")\n",
    "\n",
    "myimshow(noi, ax=axes[0])\n",
    "axes[0].set_title(\"Noisy Image\")\n",
    "\n",
    "myimshow(cle, ax=axes[1])\n",
    "axes[1].set_title(\"Clean Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created $train\\_set$ and $test\\_set$ as instances of the $NoisyBSDSDataset$ class. <br>\n",
    "Retrieved the item at index $12$ from the $test\\_set$. <br>\n",
    "Displayed the noisy and the clean images side-by-side for the $12^{th}$ index of the testing set, using the $myimshow()$ function that was given to us in the previous assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DnCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NNRegressor -> inherits from NeuralNetwork and implements criterion as MSE loss\n",
    "class NNRegressor(nt.NeuralNetwork):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NNRegressor, self).__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def criterion(self, y, d):\n",
    "        return self.mse(y, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have now defined the class $NNRegressor$ that inherits from $NeuralNetwork$. <br>\n",
    "I wrote that the $criterion$ must now be $MSELoss$ for the class $NNRegressor$.  <br>\n",
    "This class is still abstract, as the $forward()$ method is still unimplemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN(NNRegressor):\n",
    "    \n",
    "    def __init__(self, D, C=64):\n",
    "        \"\"\" Constructor\n",
    "        D - Number of repetiitons of Conv + BN + ReLU\n",
    "        C - Number of feature maps for each Conv layer\n",
    "            default - 64\n",
    "        \"\"\"\n",
    "        super(DnCNN, self).__init__()\n",
    "        self.D = D\n",
    "        self.conv = nn.ModuleList()\n",
    "        \n",
    "        # here padding=1 as we want to maintain the same size of the feature maps as given in input\n",
    "        # this translates to \"same\" in convolutions, which means that we need to pad by (n-1)/2\n",
    "        # hence, padding = (3-1)/2 = (2/2) = 1\n",
    "        self.conv.append(nn.Conv2d(3, C, 3, padding=1))\n",
    "        # COMPLETE\n",
    "        # I need to add D conv layers after this\n",
    "        for k in range(D):\n",
    "            self.conv.append(nn.Conv2d(C, C, 3, padding=1))\n",
    "        \n",
    "        # Add the final conv from 64 back to 3 feature maps\n",
    "        self.conv.append(nn.Conv2d(C, 3, 3, padding=1))\n",
    "        \n",
    "        # BN layers\n",
    "        self.bn = nn.ModuleList()\n",
    "        \n",
    "        # Append all the D Batch norm layers\n",
    "        for k in range(D):\n",
    "            self.bn.append(nn.BatchNorm2d(C))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        D = self.D\n",
    "        h = F.relu(self.conv[0](x))\n",
    "        # COMPLETE\n",
    "        # forward through all the layers\n",
    "        for k in range(D):\n",
    "            h = self.conv[k+1](h)\n",
    "            h = F.relu(self.bn[k](h))\n",
    "        # final layer forward\n",
    "        # the x is added as a skip connection - ResNet\n",
    "        y = self.conv[D+1](h) + x\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have now implemented the $DnCNN$ model, which inherits from $NNRegressor$. <br>\n",
    "As given in the question, my $1^{st}$ convolution layer will take in $3$ feature maps and output $C = 64$ feature maps of equal size after $3 x 3$ convlutions. <br>\n",
    "In order to preserve the spatial feature dimensions between each successive layer of the network, we will have to use $0-$ padding. <br>\n",
    "$$\\textbf{Zero-padding calculation}$$\n",
    "Our convolutional filter size is $3 x 3$. We need to output feature maps that are the same size as the input feature maps by using zero-padding. <br>\n",
    "For a convolutional filter of size $n = 3$, the amount of zero-padding required for \"same\" convolution is given by\n",
    "$$p = \\frac{n - 1}{2} = \\frac{3 - 1}{2} = \\frac{2}{2} = 1$$\n",
    "Hence, we give padding = $1$. <br>\n",
    "$$\\textbf{Adding the Conv layers}$$\n",
    "The $1^{st}$ conv layer converts the input $3$ channels to $C$ channels, with the padding = $1$ to maintain the same size of the feature maps through the layers as argued above. <br>\n",
    "We first append this layer to the $self.conv$ variable which is an instance of the $ModuleList$ object. <br>\n",
    "We have $D = 6$ conv layers that repeat, so we iteratively append conv layers $D$ times, where each takes in $C$ features in the input, and outputs $C$ features, to the $self.conv$ variable which is a $ModuleList$ object. <br>\n",
    "The padding is $1$ as argued above, to maintain the same size of feature maps through the layers. <br>\n",
    "The final conv layer that is appended is the one that converts $C$ input features to $3$ output features back again. The padding still remains $1$ to ensure the size of the feature maps remains the same as argued above. <br>\n",
    "Thus, we have a total of $D + 2$ conv layers in the $self.conv$ $ModuleList$, which are indexed from $0$ to $D + 1$. <br>\n",
    "$$\\textbf{Adding the BatchNorm layers}$$\n",
    "We have a total of $D$ $BatchNorm2d$ layers. We iteratively append bn layers $D$ times, where each takes in $C$ features in the input, to the $self.bn$ variable which is a $ModuleList$ object. <br>\n",
    "Thus, we have a total of $D$ bn layers in the $self.bn$ $ModuleList$, which are indexed from $0$ to $D - 1$. <br>\n",
    "$$\\textbf{Implementing the forward() method}$$\n",
    "In the $forward()$ method, as given in the question, I sequentially pass the input tensor $x$ through the $1^{st}$ conv layer, which is given by the index $0$ of the $self.conv$ $ModuleList$ object. <br>\n",
    "I then iteratively pass the tensor obtained from the previous step through the $D$ conv layers first, and then through the $D$ BN layers. <br>\n",
    "$\\textbf{NOTE: }$ Since I've already used the $1^{st}$ conv layer initially, my index in the iteration for conv layers from the $self.conv$ $ModuleList$ object is $k + 1$, where $k$ denotes the iteration index. <br>\n",
    "The index for the $BatchNorm2d$ layers remains $k$, as all my $D$ bn layers are yet to be applied. <br>\n",
    "I additionally pass the tensor obtained from each bn layer through $ReLU$. <br>\n",
    "I apply the final conv layer on the tensor obtained after $D$ iterations, using the index $D + 1$. This is the $(D + 2)^{th}$ element of the $self.conv$ $ModuleList$ object. This conv layer converts the $C$ feature maps obtained back to $3$ feature maps, with the same image size with padding = $1$ as argued above. <br>\n",
    "I then add the input tensor $x$ to this output, thus implementing my skip-connection. <br><br>\n",
    "I finally implemented the $forward()$ method of my network and thus, this class is no longer an abstract class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
