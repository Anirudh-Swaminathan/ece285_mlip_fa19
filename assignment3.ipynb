{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Anirudh Swaminathan\n",
    "### PID: A53316083\n",
    "### Email ID: aswamina@eng.ucsd.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook created by Anirudh Swaminathan from ECE department majoring in Intelligent Systems, Robotics and Control for the course ECE285 Machine Learning for Image Processing for Fall 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_dir = '/datasets/ee285f-public/caltech_ucsd_birds/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out getpass.getuser() and socket.gethostname()\n",
    "import getpass\n",
    "import socket\n",
    "\n",
    "user = getpass.getuser()\n",
    "hostname = socket.gethostname()\n",
    "print(user)\n",
    "print(hostname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created the $dataset\\_root\\_dir$ and made it point to the Bird dataset directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdsDataset(td.Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, mode=\"train\", image_size=(224, 224)):\n",
    "        super(BirdsDataset, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.mode = mode\n",
    "        \n",
    "        # data is a pandas DataFrame\n",
    "        self.data = pd.read_csv(os.path.join(root_dir, \"%s.csv\" % mode))\n",
    "        self.images_dir = os.path.join(root_dir, \"CUB_200_2011/images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"BirdsDataset(mode={}, image_size={})\".format(self.mode, self.image_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # For the idxth entry, choose the value that is in the column file_path\n",
    "        img_path = os.path.join(self.images_dir, self.data.iloc[idx]['file_path'])\n",
    "        \n",
    "        # the bounding box coordinates are at the x1, y1, x2, and y2 columns\n",
    "        bbox = self.data.iloc[idx][['x1', 'y1', 'x2', 'y2']]\n",
    "        \n",
    "        # DEBUG\n",
    "        # print(img_path)\n",
    "        # print(bbox)\n",
    "        \n",
    "        # open the image\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = img.crop([bbox[0], bbox[1], bbox[2], bbox[3]])\n",
    "        transform = tv.transforms.Compose([\n",
    "            # resize the image to image_size\n",
    "            tv.transforms.Resize(self.image_size),\n",
    "            \n",
    "            # convert to torch tensor\n",
    "            tv.transforms.ToTensor(),\n",
    "            \n",
    "            # Normalize each channel from [-1, 1]\n",
    "            tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "        \n",
    "        # apply the transform on the image\n",
    "        x = transform(img)\n",
    "        \n",
    "        # access the data from the panda DataFrame at the idxth row and the class column\n",
    "        d = self.data.iloc[idx]['class']\n",
    "        \n",
    "        # DEBUG\n",
    "        # print(d)\n",
    "        return x, d\n",
    "    \n",
    "    def number_of_classes(self):\n",
    "        return self.data['class'].max() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed the torchvision transforms compose function. <br>\n",
    "I resize the image using $tv.transforms.Resize()$ function. Then the image is converted to a torch tensor using the $tv.transforms.ToTensor()$ function. <br>\n",
    "$$\\textbf{NOTE:-} \\text{The }tv.trasforms.ToTensor() \\text{ converts the PIL image from range }(0, 255) \\text{ to a tensor of range }(0, 1)$$\n",
    "Finally, I normalize the image using the $tv.transforms.Normalize()$ function. <br>\n",
    "This function takes means and standard deviations for each channel as the input. Since each channel has been transformed to $(0, 1)$ by the $tv.transforms.ToTensor()$ function, we have the mean for each channel is $0.5$ and the standard deviation is $0.5$. <br>\n",
    "As given in the $PyTorch$ source code and documentation, the $tv.transforms.Normalize()$ function subtracts the mean for each channel from the image, and then divides by the standard deviation, so now the tensor in the range from $(0, 1)$ is converted to $\\left( \\frac{(0-0.5)}{0.5}, \\frac{(1-0.5)}{0.5} \\right)$, which is $(-1, 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myimshow(image, ax=plt):\n",
    "    image = image.to('cpu').numpy()\n",
    "    image = np.moveaxis(image, [0, 1, 2], [2, 0, 1])\n",
    "    image = (image + 1) / 2\n",
    "    image[image<0] = 0\n",
    "    image[image>1] = 1\n",
    "    h = ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set is an instance of BirdDataset\n",
    "train_set = BirdsDataset(root_dir=dataset_root_dir)\n",
    "\n",
    "# access the element at the 10th index\n",
    "x, d_x = train_set.__getitem__(10)\n",
    "\n",
    "# myimshow to display the obtained image\n",
    "myimshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(x), x.min(), x.max(), x.dtype)\n",
    "print(x.shape)\n",
    "print(d_x, type(d_x), d_x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created the object $train\\_set$ as an instance of $BirdsDataset$. <br>\n",
    "I sampled the element at index $10$ and stored it in the variable $x$. <br>\n",
    "I finally used the $myimshow()$ function that was defined to display the image $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = td.DataLoader(train_set, batch_size=16, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_loader), len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{I created } train\\_loader \\text{ that is defined to load the dataset. }$\n",
    "$\\text{The } train\\_loader \\text{ object acts on the } train\\_set \\text{.}$\n",
    "$\\text{I set the } batch\\_size \\text{ as } 16 \\text{ to sample minibatches of size } 16 \\text{.}$\n",
    "$\\text{I set shuffle = } True \\text{ to have the data reshuffled at each epoch.}$\n",
    "$\\text{The } pin\\_memory \\text{ was also set to } True \\text{ .}$\n",
    "$\\text{Setting } pin\\_memory \\text{ to } True \\text{ enables fast data transfer to CUDA-enabled GPUs.}$\n",
    "$\\text{As given in the } PyTorch \\text{ documentation, host to GPU copies are much faster when they originate from pinned (page-locked) memory.}$\n",
    "$\\text{CPU tensors and storages expose a } pin\\_memory() \\text{ method, that returns a copy of the object, with data put in a pinned region.}$\n",
    "$\\text{Since we have set the } drop\\_last \\text{ argument as } False \\text{ by default, the last minibatch is allowed to be of lower size than } 16 \\text{.}$\n",
    "$$\\textbf{Number of minibatches:- }$$\n",
    "$$\\text{Number of training minibatches per epoch } = \\frac{\\text{Total number of training images}}{\\text{Batch size}}$$\n",
    "$$\\text{Number of training minibatches per epoch } = \\frac{743}{16}$$\n",
    "$$\\text{Number of training minibatches per epoch } = 46 + 1 = 47$$\n",
    "$\\text{In one training epoch, we have } 46 \\text{ minibatches each of size } 16 \\text{ and the } 47^{th} \\text{ minibatch is of size } 7.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 1st image and label pair for the 1st 4 minibatches\n",
    "fig, axes = plt.subplots(ncols=4)\n",
    "fig.suptitle(\"1st image for 1st 4 minibatches\")\n",
    "\n",
    "for bind, mbat in enumerate(train_loader):\n",
    "    # print(len(mbat))\n",
    "    # print(type(mbat[0]), type(mbat[1]))\n",
    "    # print(mbat[0].size(), mbat[1].size())\n",
    "    \n",
    "    # The dataloader returns both the image and the label\n",
    "    # image is in the 0th index, label is 1st index\n",
    "    img = mbat[0][0, :, :, :]\n",
    "    lab = mbat[1][0]\n",
    "    # print(lab.item())\n",
    "    myimshow(img, ax=axes[bind])\n",
    "    axes[bind].text(50, 250, \"label: {}\".format(lab.item()), size=12, verticalalignment='center')\n",
    "    # axes[bind].set_ylabel(\"label: {}\".format(lab.item()))\n",
    "    axes[bind].set_title(\"mini-batch {}\".format(bind+1))\n",
    "    if bind == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 1st image and label pair for the 1st 4 minibatches\n",
    "fig, axes = plt.subplots(ncols=4)\n",
    "fig.suptitle(\"1st image for 1st 4 minibatches\")\n",
    "\n",
    "for bind, mbat in enumerate(train_loader):\n",
    "    # print(len(mbat))\n",
    "    # print(type(mbat[0]), type(mbat[1]))\n",
    "    # print(mbat[0].size(), mbat[1].size())\n",
    "    \n",
    "    # The dataloader returns both the image and the label\n",
    "    # image is in the 0th index, label is 1st index\n",
    "    img = mbat[0][0, :, :, :]\n",
    "    lab = mbat[1][0]\n",
    "    # print(lab.item())\n",
    "    myimshow(img, ax=axes[bind])\n",
    "    axes[bind].text(50, 250, \"label: {}\".format(lab.item()), size=12, verticalalignment='center')\n",
    "    # axes[bind].set_ylabel(\"label: {}\".format(lab.item()))\n",
    "    axes[bind].set_title(\"mini-batch {}\".format(bind+1))\n",
    "    if bind == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have displayed the $1^{st}$ image and label pair for the $1^{st}$ $4$ mini-batches. <br>\n",
    "I re-evaluated my cell, i.e., displayed the same information again in another cell. <br>\n",
    "I obtained different results compared to running it for the $1^{st}$ time. <br>\n",
    "This is because the $train\\_loader$ creates a random minibatch shuffle every epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = BirdsDataset(root_dir=dataset_root_dir, mode=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = td.DataLoader(val_set, batch_size=16, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created $val\\_set$ as an instance of BirdsDataset using $mode=\"val\"$. <br>\n",
    "I then created $val\\_loader$ to load the $val\\_set$. <br>\n",
    "Shuffle is not required for the validation dataset as the parameters of the network are not affected by the validation set. <br>\n",
    "Since the trained weights are just going to forward propagate the validation set images through the network just once to produce the outputs, we do not need to shuffle it. <br>\n",
    "On the other hand, shuffling the data is required for the training set of images. This is because the network has to backpropogate the errors and learn the optimal network parameters using SGD. <br>\n",
    "When using SGD, it is best to randomly shuffle the data to avoid local optima and to avoid training the network to recognize a particular sequence of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nntools as nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "help(nt.NeuralNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nt.NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I observe that on running the above line of code, I am getting a $TypeError$. <br>\n",
    "The exact error message is that I can't instantiate abstract class NeuralNetwork with abstract methods criterion and forward. <br>\n",
    "As given in the question, an abstract class does not implement all of its methods and cannot be instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNClassifier(nt.NeuralNetwork):\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def criterion(self, y, d):\n",
    "        return self.cross_entropy(y, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also defined the $NNClassifier$ that inherits from $NeuralNetwork$, and defines only the $criterion$. <br>\n",
    "Here, the $criterion$ method is implemented to be the cross-entropy loss. But this class is still abstract as it does not implement the $forward$ method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16 Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = tv.models.vgg16_bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the network\n",
    "print(vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have thus printed the network architecture using the $print(vgg)$ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the named parameters of the network\n",
    "for name, param in vgg.named_parameters():\n",
    "    print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I inspected all the named parameters of the network, and I find that all of the parameters are learnable parameters, as the $requires\\_grad$ attribute is set to $True$ for all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16Transfer(NNClassifier):\n",
    "    \n",
    "    def __init__(self, num_classes, fine_tuning=False):\n",
    "        super(VGG16Transfer, self).__init__()\n",
    "        vgg = tv.models.vgg16_bn(pretrained=True)\n",
    "        for param in vgg.parameters():\n",
    "            # if we do not want to fine tune the network, then fine_tuning=False\n",
    "            # this means that we need to freeze these VGG16 pretrained layers \n",
    "            # and NOT train them when not fine-tuning\n",
    "            param.requires_grad = fine_tuning\n",
    "        self.features = vgg.features\n",
    "        \n",
    "        # COMPLETE\n",
    "        # the average pooling is the same\n",
    "        self.avgpool = vgg.avgpool\n",
    "        # the classifier is also the same\n",
    "        self.classifier = vgg.classifier\n",
    "        \n",
    "        # CODE to change the final classifier layer\n",
    "        num_ftrs = vgg.classifier[6].in_features\n",
    "        self.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # COMPLETE the forward prop\n",
    "        f = self.features(x)\n",
    "        f = self.avgpool(f)\n",
    "        y = self.classifier(f)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created the subclass $VGG16Transfer$ that inherits from $NNClassifier$. <br>\n",
    "I copied the layers of the $VGG16$ pretrained network to my classifier. This included the Sequential features, the average pooling layer, and the Sequential classifier. I modified the final layer of my classifier to be trained specific to my task. <br>\n",
    "I finally implemented the $forward()$ method of my network and thus, this class is no longer an abstract class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = train_set.number_of_classes()\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VGG16Transfer(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the network\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have thus printed the network architecture using the $print(net)$ function. <br>\n",
    "The difference between this network and the $VGG$ pretrained net is that there is a $cross\\_entropy$ criterion for the loss. <br>\n",
    "Also, the final layer in the classifier is defined to be connecting $4096$ to $20$, which is the number of classes instead of $1000$ as defined in the original VGG network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the named parameters of the network\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I inspected all the named parameters of the network. <br>\n",
    "The only learnable parameters are for the final Fully Connected (FC) layer of the classifier, which is specific to our given task, and is different from the pre-trained $VGG$ network. <br>\n",
    "This is because we had explicitly set the $requires\\_grad$ attribute of all the other parameters of the network to $False$ to avoid training the entire network and to leverage the pre-trained weights for these layers. <br>\n",
    "Since we modified the final Fully Connected Layer of the classifier, we created a new $nn.Linear$ layer, whose $requires\\_grad$ is by default set to $True$, and thus only that layer is learnable for our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training experiment and checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationStatsManager(nt.StatsManager):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ClassificationStatsManager, self).__init__()\n",
    "        \n",
    "    def init(self):\n",
    "        super(ClassificationStatsManager, self).init()\n",
    "        self.running_accuracy = 0\n",
    "        \n",
    "    def accumulate(self, loss, x, y, d):\n",
    "        super(ClassificationStatsManager, self).accumulate(loss, x, y, d)\n",
    "        \n",
    "        # Gets the indices of the maximum activation of softmax for each sample\n",
    "        _, l = torch.max(y, 1)\n",
    "        \n",
    "        # count the running average fraction of correctly classified samples\n",
    "        self.running_accuracy += torch.mean((l == d).float())\n",
    "        \n",
    "    def summarize(self):\n",
    "        # this is the average loss when called\n",
    "        loss = super(ClassificationStatsManager, self).summarize()\n",
    "        \n",
    "        # this is the average accuracy percentage when called\n",
    "        accuracy = 100 * self.running_accuracy / self.number_update\n",
    "        return {'loss' : loss, 'accuracy' : accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a subclass $ClassificationStatsManager$ that inherits from $StatsManager$ and overloads each method. <br>\n",
    "The additional information apart from the running loss is the running accuracy that is also being tracked here. <br>\n",
    "In $init()$, the running accuracy is set to $0$. The $accumulate()$ method adds the mean accuracy for each minibatch to the running accuracy. <br>\n",
    "Finally, the $summarize()$ method is overloaded to set the accuracy to the average over all the epochs/updates. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I read the documentation for the $evaluate()$ method. $self.net$ is set to $eval$ mode by the $eval()$ function. <br>\n",
    "This ensures that the model is in evaluation mode while testing. This is to ensure that only those modules like Dropout, Batchnorm, etc. that behave differently during training and testing behave correctly. <br>\n",
    "For example, Dropout, as given in the documentation, during training, randomly zeroes some of the elements of the input tensor with probability $p$ using samples from a Bernoulli distribution. Each channel will be zeroed out independently on every forward call. <br>\n",
    "This means that during evaluation the module simply computes an identity function. <br>\n",
    "Hence, to ensure that this behaviour is followed, we call the $eval()$ function on the module first. <br>\n",
    "Once the $evaluate()$ function is computed, we again set the network to the train mode using the $train()$ method so that it can continue with the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "net = VGG16Transfer(num_classes)\n",
    "net = net.to(device)\n",
    "adam = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "stats_manager = ClassificationStatsManager()\n",
    "exp1 = nt.Experiment(net, train_set, val_set, adam,\n",
    "                     stats_manager, output_dir=\"birdclass1\",\n",
    "                     perform_validation_during_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have checked that the directory $birdclass1$ has been created. <br>\n",
    "Inspecting its contents, I find that it contains $2$ files, namely $checkpoint.pth.tar$ and $config.txt$. <br>\n",
    "Visualizing the $config.txt$ file, and also from the code in the $nntools.py$ class,  I find that it corresponds to the settings of the experiment. <br>\n",
    "So, $config.txt$ contains the network parameters, the training set, the validation set, the optimizer, the stats manager I am using, the batch size, and the boolean value for $perform\\_validation\\_during\\_training$. <br>\n",
    "The file $checkpoint.pth.tar$ corresponds to saving the $state\\_dict()$ of the model. It consists of the dictionary of key-value pairs. <br>\n",
    "The 'Net' attribute corresponds to the networks $state\\_dict()$, the 'Optimizer' corresponds to the optimizers $state\\_dict()$ and 'History' corresponds to the history of the training of the network. <br>\n",
    "The $checkpoint.pth.tar$ file was saved using the $torch.save()$ function that saves the models $save\\_dict()$ to the file with the name contained in the variable $checkpoint\\_path$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "net = VGG16Transfer(num_classes)\n",
    "net = net.to(device)\n",
    "adam = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "stats_manager = ClassificationStatsManager()\n",
    "exp1 = nt.Experiment(net, train_set, val_set, adam,\n",
    "                     stats_manager, output_dir=\"birdclass1\",\n",
    "                     perform_validation_during_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On running the same code with just a different learning rate (LR), we have accessed the same folder and the same checkpoint file. <br>\n",
    "Since the settings here are different, this means that we are supposed to create a separate folder for the same, as it is a different experiment. <br>\n",
    "Hence, a $ValueError$ is raised, with the error message $\\textbf{\"Cannot create this experiment: I found a checkpoint conflicting with the current setting.\"}$. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "net = VGG16Transfer(num_classes)\n",
    "net = net.to(device)\n",
    "adam = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "stats_manager = ClassificationStatsManager()\n",
    "exp1 = nt.Experiment(net, train_set, val_set, adam,\n",
    "                     stats_manager, output_dir=\"birdclass1\",\n",
    "                     perform_validation_during_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On changing the learning rate(LR) back to 1e-3, we can access the same checkpoint folder and file, as all the network settings are the same, including the learning rate. <br>\n",
    "This means that the checkpoint is now just loaded onto the program, as there is no conflict with the settings of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
