{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - CNNs and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Anirudh Swaminathan\n",
    "### PID: A53316083\n",
    "### Email ID: aswamina@eng.ucsd.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook created by Anirudh Swaminathan from ECE department majoring in Intelligent Systems, Robotics and Control for the course ECE285 Machine Learning for Image Processing for Fall 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3563e-19, 1.8888e+31, 4.7414e+16],\n",
      "        [4.0047e-11, 6.4097e-10, 5.8253e-10],\n",
      "        [6.4097e-10, 1.3567e-19, 4.1486e-08],\n",
      "        [1.4585e-19, 6.3369e-10, 7.9348e+17],\n",
      "        [1.3556e-19, 1.3563e-19, 1.3563e-19]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Construct 5*3 tensor and print it\n",
    "x = torch.Tensor(5, 3)\n",
    "print(x)\n",
    "\n",
    "# printing its type\n",
    "print(type(x))\n",
    "\n",
    "# printing its data type\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x$ was randomly initialized. $x$ is of type $\\textbf{torch.Tensor}$ and it's data is of type $\\text{torch.float32}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3412, 0.5528, 0.5889],\n",
      "        [0.6602, 0.6299, 0.1609],\n",
      "        [0.5155, 0.8596, 0.4628],\n",
      "        [0.1864, 0.1299, 0.4162],\n",
      "        [0.1052, 0.3734, 0.9375]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "tensor([[ 1.4837, -0.8288, -1.2014],\n",
      "        [-0.0122,  1.9979,  1.8102],\n",
      "        [ 0.3882, -1.2326, -1.2263],\n",
      "        [ 1.8649, -2.0401, -0.6632],\n",
      "        [ 0.8967,  0.1870,  0.8523]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(y)\n",
    "\n",
    "# Finding the type of y\n",
    "print(type(y))\n",
    "print(y.dtype)\n",
    "\n",
    "# Using randn() instead of rand()\n",
    "y1 = torch.randn(5, 3)\n",
    "print(y1)\n",
    "print(type(y1))\n",
    "print(y1.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y$ is a $(5, 3)$ tensor with random values distributed in a uniform distribution from $0$ to $1$<br>\n",
    "$y$ is of type $\\textbf{torch.Tensor}$ and it's data is of type torch.float32<br>\n",
    "$y_1$ is a $(5, 3)$ tensor with random values distributed as a Gaussian with mean $0$ and variance $1$. So, $y_1$ is a tensor filled with random values from a standard normal distribution<br>\n",
    "So, if we use $torch.randn()$ function instead of $torch.rand()$, we may get negative values for $torch.randn()$ but not for $torch.rand()$ function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3563e-19, 1.8888e+31, 4.7414e+16],\n",
      "        [4.0047e-11, 6.4097e-10, 5.8253e-10],\n",
      "        [6.4097e-10, 1.3567e-19, 4.1486e-08],\n",
      "        [1.4585e-19, 6.3369e-10, 7.9348e+17],\n",
      "        [1.3556e-19, 1.3563e-19, 1.3563e-19]], dtype=torch.float64)\n",
      "tensor([[0.3412, 0.5528, 0.5889],\n",
      "        [0.6602, 0.6299, 0.1609],\n",
      "        [0.5155, 0.8596, 0.4628],\n",
      "        [0.1864, 0.1299, 0.4162],\n",
      "        [0.1052, 0.3734, 0.9375]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = x.double()\n",
    "y = y.double()\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type displayed when we print $x$ and $y$ are $torch.float64$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tensors with values directly\n",
    "x = torch.Tensor([[-0.1859, 1.3970, 0.5236],\n",
    "[ 2.3854, 0.0707, 2.1970],\n",
    "[-0.3587, 1.2359, 1.8951],\n",
    "[-0.1189, -0.1376, 0.4647],\n",
    "[-1.8968, 2.0164, 0.1092]])\n",
    "\n",
    "y = torch.Tensor([[ 0.4838, 0.5822, 0.2755],\n",
    "[ 1.0982, 0.4932, -0.6680],\n",
    "[ 0.7915, 0.6580, -0.5819],\n",
    "[ 0.3825, -1.1822, 1.5217],\n",
    "[ 0.6042, -0.2280, 1.3210]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3]) torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of the two tensors x and y\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of $x$ is $(5, 3)$. <br>\n",
    "Shape of $y$ is $(5, 3)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack 2 tensors\n",
    "z = torch.stack((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1859,  1.3970,  0.5236],\n",
      "         [ 2.3854,  0.0707,  2.1970],\n",
      "         [-0.3587,  1.2359,  1.8951],\n",
      "         [-0.1189, -0.1376,  0.4647],\n",
      "         [-1.8968,  2.0164,  0.1092]],\n",
      "\n",
      "        [[ 0.4838,  0.5822,  0.2755],\n",
      "         [ 1.0982,  0.4932, -0.6680],\n",
      "         [ 0.7915,  0.6580, -0.5819],\n",
      "         [ 0.3825, -1.1822,  1.5217],\n",
      "         [ 0.6042, -0.2280,  1.3210]]]) torch.float32 torch.Size([2, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(z, z.dtype, z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1859,  1.3970,  0.5236],\n",
      "        [ 2.3854,  0.0707,  2.1970],\n",
      "        [-0.3587,  1.2359,  1.8951],\n",
      "        [-0.1189, -0.1376,  0.4647],\n",
      "        [-1.8968,  2.0164,  0.1092],\n",
      "        [ 0.4838,  0.5822,  0.2755],\n",
      "        [ 1.0982,  0.4932, -0.6680],\n",
      "        [ 0.7915,  0.6580, -0.5819],\n",
      "        [ 0.3825, -1.1822,  1.5217],\n",
      "        [ 0.6042, -0.2280,  1.3210]]) torch.Size([10, 3])\n",
      "tensor([[-0.1859,  1.3970,  0.5236,  0.4838,  0.5822,  0.2755],\n",
      "        [ 2.3854,  0.0707,  2.1970,  1.0982,  0.4932, -0.6680],\n",
      "        [-0.3587,  1.2359,  1.8951,  0.7915,  0.6580, -0.5819],\n",
      "        [-0.1189, -0.1376,  0.4647,  0.3825, -1.1822,  1.5217],\n",
      "        [-1.8968,  2.0164,  0.1092,  0.6042, -0.2280,  1.3210]]) torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "# Now, compare it with torch.cat()\n",
    "z1 = torch.cat((x, y), 0)\n",
    "z2 = torch.cat((x, y), 1)\n",
    "print(z1, z1.shape)\n",
    "print(z2, z2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the tensor $z$ is $(2, 5, 3)$. <br>\n",
    "$torch.stack()$ stacks its arguments on a new dimension, i.e., on top of one another in this case. <br>\n",
    "\n",
    "We also compared it to $torch.cat()$. <br>\n",
    "In $torch.cat((x, y), 0)$, the tensor $y$ is concatenated to tensor $x$ along axis $0$, i.e., it is concatenated along the row. This results in a tensor that is of the shape $(10, 3)$ that is obtained by combining the two tensors, each of shape $(5, 3)$ row-wise. The output of this $torch.cat()$ is still the same dimension $(2D)$. <br>\n",
    "\n",
    "Similarly, in $torch.cat((x, y), 1)$, the tensor $y$ is concatenated to tensor $x$ along axis $1$, i.e., it is concatenated along the column. This results in a tensor that is of the shape $(5, 6)$ that is obtained by combining the two tensors, each of shape $(5, 3)$ column-wise. The output of this $torch.cat()$ is still the same dimension $(2D)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The element of the 5th row and 3rd column in 2d tensor y: 1.3209999799728394\n",
      "Accessing the same element in the 3d tensor z, we have 1.3209999799728394\n"
     ]
    }
   ],
   "source": [
    "# Accessing the element of the 5th row and 3rd column in 2d tensor y\n",
    "ele = y[4, 2]\n",
    "print(\"The element of the 5th row and 3rd column in 2d tensor y:\", ele.item())\n",
    "\n",
    "# Accessing the same element in the 3D tensor z\n",
    "ele_3d = z[1, 4, 2]\n",
    "print(\"Accessing the same element in the 3d tensor z, we have\", ele_3d.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we were able to access the element of the $5^{th}$ row and $3^{rd}$ column in the $2D$ tensor $y$. <br>\n",
    "We were also able to access the same element from the $3D$ tensor $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing all elements corresponding to the 5th row and 3rd column in z: tensor([0.1092, 1.3210])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Print all elements corresponding to the 5th row and 3rd column in z\n",
    "eles = z[:, 4, 2]\n",
    "print(\"Printing all elements corresponding to the 5th row and 3rd column in z:\", eles)\n",
    "print(eles.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are $2$ elements in $z$ that correspond to the $5^{th}$ row and $3^{rd}$ column of the tensor $z$. <br>\n",
    "This is beacause $z$ is the stacked tensor of $x$ and $y$. Hence, the $1^{st}$ returned element corresponds to the element at the $5^{th}$ row and $3^{rd}$ column of the tensor $x$, and the $2^{nd}$ returned element corresponds to the element at the $5^{th}$ row and $3^{rd}$ column of the tensor $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n"
     ]
    }
   ],
   "source": [
    "print(x + y)\n",
    "print(torch.add(x, y))\n",
    "print(x.add(y))\n",
    "torch.add(x, y, out=x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the $4$ methods of addition print the same output. <br>\n",
    "Also, all the $4$ methods are equivalent. They all take in 2 tensors x and y, and then output a new tensor. <br>\n",
    "They all do NOT modify the tensors $x$ and $y$. <br>\n",
    "Tensor $x$ seems modified in the last statement only because $out=x$ was specified, which meant that $torch$ stored the output of the addition operation between $x$ and $y$ in the variable $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "tensor([[-0.2910, -0.5872,  0.2615, -0.4767],\n",
      "        [ 1.7549, -1.2167, -0.7197,  0.8474],\n",
      "        [-0.4785, -1.1303, -1.3507,  0.2692],\n",
      "        [-0.0975, -0.0522, -0.7660,  1.2422]])\n",
      "tensor([-0.2910, -0.5872,  0.2615, -0.4767,  1.7549, -1.2167, -0.7197,  0.8474,\n",
      "        -0.4785, -1.1303, -1.3507,  0.2692, -0.0975, -0.0522, -0.7660,  1.2422])\n",
      "tensor([[-0.2910, -0.5872,  0.2615, -0.4767,  1.7549, -1.2167, -0.7197,  0.8474],\n",
      "        [-0.4785, -1.1303, -1.3507,  0.2692, -0.0975, -0.0522, -0.7660,  1.2422]])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor whose values are sampled from a Normal Distribution with mean 0 and variance 1\n",
    "x = torch.randn(4, 4)\n",
    "\n",
    "# store a reshaped version of x in y such that it is a 1D tensor of size 16\n",
    "y = x.view(16)\n",
    "\n",
    "# store the reshaped version of x in z such that it is a 2D tensor of size (2, 8)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $1^{st}$ statement creates tensor $x$ of shape $(4, 4)$ using the $randn()$ function whose values are sampled from a Normal Distribution with $\\mu = 0$ and $\\sigma^2 = 1$. <br>\n",
    "The $2^{nd}$ statement stores a reshaped version of $x$ in $y$ such that it is a $1D$ tensor of size $16$. <br>\n",
    "The $3^{rd}$ statement stores a reshaped version of $x$ in $z$ such that it is a $2D$ tensor of size $(2, 8)$. <br>\n",
    "The $-1$ in the argument for the $view()$ function states that the $1^{st}$ dimension of $z$ should be inferred by $torch$ directly given that the $2^{nd}$ dimension of $z$ is $8$. <br>\n",
    "This conversion is just $4 * 4 = 16; \\frac{16}{8} = 2$. Thus, the $1^{st}$ dimension of $z$ should be $2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10]) torch.Size([2, 100])\n",
      "torch.Size([1, 100]) torch.Size([100, 2])\n",
      "torch.Size([1, 2])\n",
      "tensor([[ -7.5519, -10.7117]])\n"
     ]
    }
   ],
   "source": [
    "# Generate random x of dimension 10*10\n",
    "x = torch.randn(10, 10)\n",
    "\n",
    "# Generate random y of dimension 2*100\n",
    "y = torch.randn(2, 100)\n",
    "print(x.size(), y.size())\n",
    "\n",
    "# reshape x to become a row vector and make it compatible for matrix multiplication\n",
    "x = x.view(1, 100)\n",
    "\n",
    "# reshape y to become a matrix compatible for matrix multiplication with x\n",
    "y = y.view(100, 2)\n",
    "print(x.size(), y.size())\n",
    "\n",
    "# perform row vector by matrix multiplication\n",
    "z = torch.mm(x, y)\n",
    "print(z.size())\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a tensor $x$ of size $(10, 10)$ and tensor $y$ of size $(2, 100)$. <br>\n",
    "We then reshaped the tensor $x$ to row vector of size $(1, 100)$. <br>\n",
    "Tensor $y$ was also reshaped to size $(100, 2)$ to make it conformable for matrix multiplication with $x$. <br>\n",
    "Finally, the result of the matrix multiplication carried out by $torch.mm(x, y)$ is stored in the tensor $z$. <br>\n",
    "Tensor $z$ is of size $(1, 100)*(100, 2) = (1, 2)$. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'torch.Tensor'> <class 'numpy.ndarray'>\n",
      "torch.float32 float32\n",
      "torch.Size([5]) (5,)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "\n",
    "print(type(a), type(b))\n",
    "print(a.dtype, b.dtype)\n",
    "print(a.size(), b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable $a$ is a $1D$ tensor of size $(5)$ carrying data of type $torch.float32$. Variable $b$ is a $1D$ numpy array of shape $(5,)$ carrying data of type $float32$. <br>\n",
    "$b$ is the $numpy$ version of tensor $a$ and both carry the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 1., 1., 1., 1.])\n",
      "[2. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a[0] += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor $a$ and numpy array $b$ both share the same underlying memory location. <br>\n",
    "Modifying $a$ changes $b$ and modifying $b$ changes $a$ if the tensor $a$ is on the CPU, which is the case here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 2., 2., 2., 2.])\n",
      "[3. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $add\\_(1)$ modifies $a$ in-place, thus modifying numpy array $b$ also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 3., 3., 3., 3.])\n",
      "[4. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a[:] += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This statement modifies $a$, thus modifying numpy $b$ also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 4., 4., 4., 4.])\n",
      "[4. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a = a.add(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The satement $a.add(1)$ adds $1$ to $a$ and returns a new tensor. <br>\n",
    "Since we store the result in $a$, only $a$ is now the variable that points to the new tensor output, but the underlying memory location is not modified. Thus, $b$ is not modified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy array $a$ and tensor $b$ share the same underlying location. <br>\n",
    "Modifying $a$ changes $b$ and vice-versa if the tensor is in the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "torch.Size([5, 3]) torch.float32 cuda:0\n",
      "torch.Size([5, 3]) torch.float32 cuda:0\n",
      "torch.Size([5, 3]) torch.float32 cuda:0\n",
      "tensor([[-0.8340, -0.2621, -1.5960],\n",
      "        [ 0.4451,  2.2970, -0.5133],\n",
      "        [ 2.9873,  0.7170, -0.3918],\n",
      "        [ 0.1028,  0.1764,  0.6040],\n",
      "        [ 0.6886,  0.1032, -0.7320]], device='cuda:0')\n",
      "tensor([[-0.4412,  0.2622, -1.3004],\n",
      "        [-0.6348,  0.8524, -1.7512],\n",
      "        [ 0.6262, -0.7539,  0.8823],\n",
      "        [ 0.2665,  0.1195,  1.0902],\n",
      "        [-0.2456,  1.0017,  0.8983]], device='cuda:0')\n",
      "tensor([[-1.2752e+00,  1.3217e-04, -2.8964e+00],\n",
      "        [-1.8975e-01,  3.1494e+00, -2.2645e+00],\n",
      "        [ 3.6135e+00, -3.6901e-02,  4.9054e-01],\n",
      "        [ 3.6936e-01,  2.9586e-01,  1.6942e+00],\n",
      "        [ 4.4299e-01,  1.1049e+00,  1.6633e-01]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# GPU experiments\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# Create a tensor on CPU and then move it to GPU\n",
    "x = torch.randn(5, 3).to(device)\n",
    "\n",
    "# Create a tensor directly on the GPU\n",
    "y = torch.randn(5, 3, device=device)\n",
    "z = x + y\n",
    "print(x.size(), x.dtype, x.device)\n",
    "print(y.size(), y.dtype, y.device)\n",
    "print(z.size(), z.dtype, z.device)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor $x$ is first created in the CPU and then transferred to the GPU using the $.to()$ command. <br>\n",
    "Tensor $y$ is created in the GPU directly with the $device$ argument in the $randn()$ function. <br>\n",
    "I feel that the allocation instruction for $y$ is more efficient than the one for $x$ as creating a tensor on CPU and then transferring it to GPU is $2$ steps, with the additional overhead of transferring it between devices. <br>\n",
    "Directly allocating the tensor to the GPU would avoid these extra steps, and hence would be more efficient comparatively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.2751775e+00  1.3217330e-04 -2.8964458e+00]\n",
      " [-1.8974915e-01  3.1494401e+00 -2.2645404e+00]\n",
      " [ 3.6135235e+00 -3.6900699e-02  4.9054387e-01]\n",
      " [ 3.6936343e-01  2.9585814e-01  1.6942282e+00]\n",
      " [ 4.4298744e-01  1.1048564e+00  1.6632962e-01]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-abcfc2eaf4a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# The following line produces an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# This line runs fine\n",
    "print(z.cpu().numpy())\n",
    "\n",
    "# The following line produces an error\n",
    "print(z.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the $1^{st}$ line, the tensor $z$ is copied to CPU first using the $.cpu()$ function. Then, it is converted to a numpy array in the CPU. <br>\n",
    "The $2^{nd}$ line throws a $TypeError$ as $torch$ can't convert the CUDA tensor to numpy directly. It means that the conversion has to be carried out in the CPU, and hence $z.cpu()$ has to be used first before the conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd: automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "None\n",
      "None\n",
      "None\n",
      "<AddBackward0 object at 0x7f95530e7ef0>\n"
     ]
    }
   ],
   "source": [
    "print(y.requires_grad)\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(x.grad_fn)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the $requires\\_grad$ attribute of $x$ is $True$ and we are performing operations on $x$ to obtain $y$, $y$ will have its attribute $requires\\_grad$ set to $True$ automatically. <br>\n",
    "The $grad$ attributes of both the tensors $x$ and $y$ are $None$. This is because the gradient has not been computed yet for these tensors using the $.backward()$ function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "f = z.mean()\n",
    "print(z, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that $z$ has elements that are the square of each elemnent of $y$ times $3$. <br>\n",
    "The tensor $f$ contains that value that is the mean of the elements of $z$. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now discuss the relation between $f$ and the $4$ entries of $x$ - namely $x_1, x_2, x_3, and x_4$ <br>\n",
    "$$f = f(x_1, x_2, x_3, x_4)$$\n",
    "We know that\n",
    "$$x = \\begin{bmatrix}\n",
    "x_1 & x_2 \\\\\n",
    "x_3 & x_4\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Given, $$y = x + 2$$\n",
    "So, $$y = \\begin{bmatrix}\n",
    "x_1 + 2 & x_2 + 2 \\\\\n",
    "x_3 + 2 & x_4 + 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Given, $$z = y * y * 3$$\n",
    "So, $$z = \\begin{bmatrix}\n",
    "x_1 + 2 & x_2 + 2 \\\\\n",
    "x_3 + 2 & x_4 + 2\n",
    "\\end{bmatrix} \\otimes \\begin{bmatrix}\n",
    "x_1 + 2 & x_2 + 2 \\\\\n",
    "x_3 + 2 & x_4 + 2\n",
    "\\end{bmatrix} * 3$$\n",
    "$$\\implies z = \\begin{bmatrix}\n",
    "3(x_1 + 2)^2 & 3(x_2 + 2)^2 \\\\\n",
    "3(x_3 + 2)^2 & 3(x_4 + 2)^2\n",
    "\\end{bmatrix}$$\n",
    "Given, $$f = z.mean()$$\n",
    "So, $$f = \\frac{3(x_1 + 2)^2 + 3(x_2 + 2)^2 + 3(x_3 + 2)^2 + 3(x_4 + 2)^2}{4}$$\n",
    "$$\\implies f = \\frac{3}{4} * \\left[ x_1^2 + 4x_1 + 4 + x_2^2 + 4x_2 + 4 + x_3^2 + 4x_3 + 4 + x_4^2 + 4x_4 + 4 \\right]$$\n",
    "Hence, finally we have that \n",
    "$$f(x_1, x_2, x_3, x_4) = \\frac{3}{4}x_1^2 + \\frac{3}{4}x_2^2 + \\frac{3}{4}x_3^2 + \\frac{3}{4}x_4^2 + 3x_1 + 3x_2 + 3x_3 + 3x_4 + 12$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "f.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None None tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n",
      "<MeanBackward0 object at 0x7f95530e7080> <MulBackward0 object at 0x7f95530f6a90> <AddBackward0 object at 0x7f95530f67f0> None\n",
      "True True True True\n"
     ]
    }
   ],
   "source": [
    "print(f.grad, z.grad, y.grad, x.grad)\n",
    "print(f.grad_fn, z.grad_fn, y.grad_fn, x.grad_fn)\n",
    "print(f.requires_grad, z.requires_grad, y.requires_grad, x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the code above, we compute the gradient of the tensor $f$ with respect to $x$ using autograd. <br>\n",
    "We find that $$\\nabla_xf(x) = \\left( \\frac{\\delta f(x)}{\\delta x} \\right)^T = \\begin{bmatrix}\n",
    "4.5000 & 4.5000 \\\\\n",
    "4.5000 & 4.5000\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given, $$\\left( \\nabla_xf(x) \\right)_i = \\frac{\\delta f(x_1, x_2, x_3, x_4)}{\\delta x_i}$$\n",
    "From question 18, we know that $$f(x_1, x_2, x_3, x_4) = \\frac{3}{4}x_1^2 + \\frac{3}{4}x_2^2 + \\frac{3}{4}x_3^2 + \\frac{3}{4}x_4^2 + 3x_1 + 3x_2 + 3x_3 + 3x_4 + 12$$\n",
    "Taking $i=1$, $$\\left( \\nabla_xf(x) \\right)_1 = \\frac{\\delta f(x_1, x_2, x_3, x_4)}{\\delta x_1}$$\n",
    "$$\\left( \\nabla_xf(x) \\right)_1 = \\frac{\\delta \\left( \\frac{3}{4}x_1^2 + \\frac{3}{4}x_2^2 + \\frac{3}{4}x_3^2 + \\frac{3}{4}x_4^2 + 3x_1 + 3x_2 + 3x_3 + 3x_4 + 12 \\right)}{\\delta x_1}$$\n",
    "$$\\left( \\nabla_xf(x) \\right)_1 = \\frac{3}{2}x_1 + 3$$\n",
    "\n",
    "Taking $i=2$, $$\\left( \\nabla_xf(x) \\right)_2 = \\frac{\\delta f(x_1, x_2, x_3, x_4)}{\\delta x_2}$$\n",
    "$$\\left( \\nabla_xf(x) \\right)_2 = \\frac{\\delta \\left( \\frac{3}{4}x_1^2 + \\frac{3}{4}x_2^2 + \\frac{3}{4}x_3^2 + \\frac{3}{4}x_4^2 + 3x_1 + 3x_2 + 3x_3 + 3x_4 + 12 \\right)}{\\delta x_2}$$\n",
    "$$\\left( \\nabla_xf(x) \\right)_2 = \\frac{3}{2}x_2 + 3$$\n",
    "\n",
    "Taking $i=3$, $$\\left( \\nabla_xf(x) \\right)_3 = \\frac{\\delta f(x_1, x_2, x_3, x_4)}{\\delta x_3}$$\n",
    "$$\\left( \\nabla_xf(x) \\right)_3 = \\frac{\\delta \\left( \\frac{3}{4}x_1^2 + \\frac{3}{4}x_2^2 + \\frac{3}{4}x_3^2 + \\frac{3}{4}x_4^2 + 3x_1 + 3x_2 + 3x_3 + 3x_4 + 12 \\right)}{\\delta x_3}$$\n",
    "$$\\left( \\nabla_xf(x) \\right)_3 = \\frac{3}{2}x_3 + 3$$\n",
    "\n",
    "Taking $i=4$, $$\\left( \\nabla_xf(x) \\right)_4 = \\frac{\\delta f(x_1, x_2, x_3, x_4)}{\\delta x_4}$$\n",
    "$$\\left( \\nabla_xf(x) \\right)_4 = \\frac{\\delta \\left( \\frac{3}{4}x_1^2 + \\frac{3}{4}x_2^2 + \\frac{3}{4}x_3^2 + \\frac{3}{4}x_4^2 + 3x_1 + 3x_2 + 3x_3 + 3x_4 + 12 \\right)}{\\delta x_4}$$\n",
    "$$\\left( \\nabla_xf(x) \\right)_4 = \\frac{3}{2}x_4 + 3$$\n",
    "\n",
    "Thus, we have $$\\nabla_xf(x) = \\begin{bmatrix}\n",
    "\\left( \\nabla_xf(x) \\right)_1 & \\left( \\nabla_xf(x) \\right)_2 \\\\\n",
    "\\left( \\nabla_xf(x) \\right)_3 & \\left( \\nabla_xf(x) \\right)_4\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\\implies \\nabla_xf(x) = \\begin{bmatrix}\n",
    "\\frac{3}{2}x_1 + 3 & \\frac{3}{2}x_2 + 3 \\\\\n",
    "\\frac{3}{2}x_3 + 3 & \\frac{3}{2}x_4 + 3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Here, in this example, we have taken the tensor $x$ to be $2 \\times 2$ matrix filled with just $1$. <br>\n",
    "Hence, we have $$x = \\begin{bmatrix}\n",
    "x_1 & x_2 \\\\\n",
    "x_3 & x_4\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix}$$\n",
    "Thus, we have $x_1 = 1, x_2 = 1, x_3 = 1, x_4 = 1$. <br>\n",
    "This means that we have $$\\nabla_xf(x) = \\begin{bmatrix}\n",
    "\\frac{3}{2}x_1 + 3 & \\frac{3}{2}x_2 + 3 \\\\\n",
    "\\frac{3}{2}x_3 + 3 & \\frac{3}{2}x_4 + 3\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\frac{3}{2}1 + 3 & \\frac{3}{2}1 + 3 \\\\\n",
    "\\frac{3}{2}1 + 3 & \\frac{3}{2}1 + 3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\\implies \\nabla_xf(x) = \\begin{bmatrix}\n",
    "4.5 & 4.5 \\\\\n",
    "4.5 & 4.5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This is consistent with the output of the command $x.grad$ in question $19$, where we obtained $$\\nabla_xf(x) = \\left( \\frac{\\delta f(x)}{\\delta x} \\right)^T = \\begin{bmatrix}\n",
    "4.5000 & 4.5000 \\\\\n",
    "4.5000 & 4.5000\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Hence, we have mathematically verified that autograd produces the correct answer for computing the derivatives of the scalar $f$ with respect to the tensor $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import MNISTtools\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Normalize MNIST Images\n",
    "def normalize_MNIST_images(x):\n",
    "    # Convert the uint8 input into float32 for ease of normalization\n",
    "    fl_x = x.astype(np.float32)\n",
    "    \n",
    "    # Normalize [0 to 255] to [-1 to 1]\n",
    "    # This means mapping 0 to -1, 255 to 1, and 127.5 to 0\n",
    "    ret = 2*(fl_x - 255/2.0) / 255\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training data\n",
    "xtrain, ltrain = MNISTtools.load(path='./datasets/MNIST')\n",
    "\n",
    "# Normalize the training images\n",
    "norm_x_train = normalize_MNIST_images(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the testing data\n",
    "xtest, ltest = MNISTtools.load(dataset='testing', path='./datasets/MNIST')\n",
    "\n",
    "# Normalize the test images\n",
    "norm_x_test = normalize_MNIST_images(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reused the code from Assignment $1$ to load and normalize the MNIST testing and training data, and have converted the training and testing labels to one-hot encoded vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1, 60000)\n",
      "(28, 28, 1, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the normalized training dataset to torch format\n",
    "train_reshaped = np.reshape(norm_x_train, (28, 28, 1, 60000))\n",
    "test_reshaped = np.reshape(norm_x_test, (28, 28, 1, 10000))\n",
    "\n",
    "print(train_reshaped.shape)\n",
    "print(test_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n",
      "(10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Make the numpy ndarrays compatible with torch format of Batch size * Number of input channels * Image Height * Image width\n",
    "xtrain = np.moveaxis(train_reshaped, [0, 1, 2, 3], [2, 3, 1, 0])\n",
    "xtest = np.moveaxis(test_reshaped, [0, 1, 2, 3], [2, 3, 1, 0])\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we have reorganised the numpy arrays $xtrain$ and $xtest$ such that they conform to the torch conventions for tensors, which is Batch size * Number of input channels * Image Height * Image width. <br>\n",
    "As given in the hint, we initially reshaped the training data to the shape $(28, 28, 1, 60000)$ and the testing data to the shape $(28, 28, 1, 10000)$ respectively. <br>\n",
    "We then used $np.moveaxis()$ to move the $0^{th}$ dimension, i.e., the image height to $2^{nd}$ position, the $1^{st}$ dimension, i.e., the image width to $3^{rd}$ position, the $2^{nd}$ dimension, i.e., the number of channels to the $1^{st}$ position, and the $3^{rd}$ dimension, i.e., the batch size to the $0^{th}$ position. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# check if our reorganization of training data was correct\n",
    "MNISTtools.show(xtrain[42, 0, :, :])\n",
    "print(ltrain[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# check if our reorganization of testing data was correct\n",
    "MNISTtools.show(xtest[42, 0, :, :])\n",
    "print(ltest[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we have verified that our reorganization was indeed correct for both the training and testing set of images, as we displayed the images at index $42$ for both, and the corresponding labels for both were correctly displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap all the data into a torch tensor\n",
    "xtrain = torch.from_numpy(xtrain)\n",
    "ltrain = torch.from_numpy(ltrain)\n",
    "xtest = torch.from_numpy(xtest)\n",
    "ltest = torch.from_numpy(ltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.float32 torch.Size([60000, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.int64 torch.Size([60000])\n",
      "<class 'torch.Tensor'> torch.float32 torch.Size([10000, 1, 28, 28])\n",
      "<class 'torch.Tensor'> torch.int64 torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(type(xtrain), xtrain.dtype, xtrain.size())\n",
    "print(type(ltrain), ltrain.dtype, ltrain.size())\n",
    "print(type(xtest), xtest.dtype, xtest.size())\n",
    "print(type(ltest), ltest.dtype, ltest.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now converted the dataset into torch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN) for MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given, our LeNet is composed of $2$ convolutional layers, activated by ReLU followed by MaxPooling. <br>\n",
    "Then we have $3$ fully connected layers to get the output as $10$ neurons in the final layer. <br>\n",
    "\n",
    "i. The first convolutional layer connects the input image to $6$ feature maps with $5 \\times 5$ convolutions $(K = 5)$ and followed by ReLU. <br>\n",
    "Since for input images of size W $\\times$ H, the output feature maps have size \\[W  K + 1\\] $\\times$ \\[H  K + 1\\], we have the size of the feature maps after the $1^{st}$ convolutional layer as $60000 \\times 6 \\times 24 \\times 24$ <br><br>\n",
    "\n",
    "ii. The $1^{st}$ maxpooling layer has $(L = 2)$. Since for input images of size W $\\times$ H, the output feature maps have size $\\left[ \\frac{W}{L} \\right] \\times \\left[ \\frac{H}{L} \\right]$, we have the size of the feature maps after the $1^{st}$ maxpooling layer as $60000 \\times 6 \\times 12 \\times 12$ <br><br>\n",
    "\n",
    "iii. The second convolutional layer connects the $6$ input channels to $16$ output channels with $5 \\times 5$ convolutions and followed by ReLU. <br>\n",
    "Since for input images of size W $\\times$ H, the output feature maps have size \\[W  K + 1\\] $\\times$ \\[H  K + 1\\], we have the size of the feature maps after the $2^{nd}$ convolutional layer as $60000 \\times 16 \\times 8 \\times 8$ <br><br>\n",
    "\n",
    "iv. The $2^{nd}$ maxpooling layer has $(L = 2)$. Since for input images of size W $\\times$ H, the output feature maps have size $\\left[ \\frac{W}{L} \\right] \\times \\left[ \\frac{H}{L} \\right]$, we have the size of the feature maps after the $2^{nd}$ maxpooling layer as $60000 \\times 16 \\times 4 \\times 4$ <br><br>\n",
    "\n",
    "v. The fully connected layer connects the the $16$ feature maps to $120$ output units. Since each feature map is of size $4 \\times 4$, we have the total number of neurons as $16 * 4 * 4 = 256$. <br>\n",
    "Hence, the third layer has $256$ input units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This is our neural network class that inherits from nn.Module\n",
    "class LeNet(nn.Module):\n",
    "    \n",
    "    # Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        # The first convolutional layer having 6 filters, each of size (5, 5)\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        \n",
    "        # The second convolutional layer having 16 filters each of size (5, 5)\n",
    "        # that operates on the previous layer having 6 filters\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # The first fully connected layer from 16*4*4 after the maxpooling after the second convolutional layer\n",
    "        # to 120 units. So, we have 256 input units and 120 output units in this Linear Layer\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        \n",
    "        # The second fully connected layer from 120 inputs to 84 outputs\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        \n",
    "        # The third fully connected layer from 84 inputs to 10 outputs\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    # Here, we define one forward pass through the network\n",
    "    def forward(self, x):\n",
    "        # We pass the input to the 1st convolutional layer. We next apply ReLU.\n",
    "        # We finally perform (2*2) maxpooling on it\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        \n",
    "        # We then pass this output to the 2nd convolutional layer. We next apply ReLU.\n",
    "        # We finally perform (2*2) maxpooling on it\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        \n",
    "        # We now flatten the tensors from the second maxpooling layer from 16*4*4 to 256\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "        # We then pass the flattened tensor x to the 1st Fully Connected Layer. We next apply ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # We next pass this through the next fully connected layer from 120 to 84 units\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # We finally pass this output from 84 units to 10 units using the Linear Layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)\n",
    "    \n",
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{Network Definition}$$\n",
    "We have thus completed the code that defines the network architecture of our model.\n",
    "We defined the $1^{st}$ convolutional layer having $6$ filters, each of size $(5, 5)$ using $nn.Conv2d(1, 6, 5)$. <br>\n",
    "We then defined the $2^{nd}$ convolutional layer having $16$ filters each of size $(5, 5)$. Each operates on the previous layer having $6$ filters. Hence, we defined that layer using $nn.Conv2d(6, 16, 5)$. <br>\n",
    "We defined the first fully connected layer from $16*4*4$ after the maxpooling after the $2^{nd}$ convolutional layer to $120$ units. So, we have $256$ input units and $120$ output units in this Linear Layer. We define this layer using $nn.Linear(256, 120)$. <br>\n",
    "The $2^{nd}$ fully connected layer is from $120$ inputs to $84$ outputs. We define it using $nn.Linear(120, 84)$. <br>\n",
    "The $3^{rd}$ Linear layer is from $84$ inputs to $10$ outputs. We define it using the $nn.Linear(84, 10)$. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{Forward Pass}$$\n",
    "The forward pass through the network is run as follows. <br>\n",
    "We pass the input to the $1^{st}$ convolutional layer. We next apply ReLU. We finally perform $(2*2)$ maxpooling on it. We use $F.max\\_pool2d(F.relu(self.conv1(x)), (2, 2))$ for this purpose. <br>\n",
    "We then pass this output to the $2^{nd}$ convolutional layer. We next apply ReLU. We finally perform $(2*2)$ maxpooling on it. We use $F.max\\_pool2d(F.relu(self.conv2(x)), (2, 2))$. <br>\n",
    "We now flatten the tensors from the $2^{nd}$ maxpooling layer from $16*4*4$ to $256$. We use $x.view(-1, self.num\\_flat\\_features(x))$. <br>\n",
    "The $num\\_flat\\_features(x)$ function returns the number of neurons that are present if we flatten the tensor $x$.<br>\n",
    "We then pass the flattened tensor $x$ to the $1^{st}$ Fully Connected Layer. We next apply ReLU. We use $F.relu(self.fc1(x))$. <br>\n",
    "We next pass this through the next fully connected layer from $120$ to $84$ units. We use $F.relu(self.fc2(x))$. <br>\n",
    "We finally pass this output from $84$ units to $10$ units using the Linear Layer. We use $self.fc3(x)$. <br><br>\n",
    "Hence, we have interpreted and completed the code for initializing our LeNet network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5]) True\n",
      "conv1.bias torch.Size([6]) True\n",
      "conv2.weight torch.Size([16, 6, 5, 5]) True\n",
      "conv2.bias torch.Size([16]) True\n",
      "fc1.weight torch.Size([120, 256]) True\n",
      "fc1.bias torch.Size([120]) True\n",
      "fc2.weight torch.Size([84, 120]) True\n",
      "fc2.bias torch.Size([84]) True\n",
      "fc3.weight torch.Size([10, 84]) True\n",
      "fc3.bias torch.Size([10]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learnable parameters as returned by the $net.named\\_parameters()$ function is as follows:-\n",
    "$$conv1.weight, conv1.bias, conv2.weight,conv2.bias, fc1.weight, fc1.bias, fc2.weight, fc2.bias, fc3.weight, fc3.bias$$\n",
    "These are the weights and biases for the $2$ Convolution layers, as well as for all the $3$ fully connected layers. <br>\n",
    "The $requires\\_grad$ attribute is set to True for all the parameters, and hence, the gradients are going to be tracked for all the parameters. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yinit = net(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.9200)\n"
     ]
    }
   ],
   "source": [
    "_, lpred = yinit.max(1)\n",
    "\n",
    "# calculate the precentage of correctly predicted labels for the initial run\n",
    "init_acc = 100 * (ltest == lpred).float().mean()\n",
    "print(init_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have computed the labels for the randomly initialized network, and then computed the percentage of correctly predicted samples and displayed it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 29 and Question 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    # training set size\n",
    "    N = xtrain.size()[0]\n",
    "    \n",
    "    # number of minibatches\n",
    "    NB = int((N+B-1)/B)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # learning rate lr is gamma, which is the step size\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=gamma, momentum=rho)\n",
    "    \n",
    "    for epoch in range(T):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # shuffle the indices to access the data\n",
    "        shuffled_indices = np.random.permutation(range(N))\n",
    "        for k in range(NB):\n",
    "            # Extract the k-th minibatch from xtrain and ltrain\n",
    "            # get the shuffled indices for a given minibatch\n",
    "            minibatch_indices = shuffled_indices[B*k:min(B*(k+1), N)]\n",
    "            inputs = xtrain[minibatch_indices, :, :, :]\n",
    "            labels = ltrain[minibatch_indices]\n",
    "            \n",
    "            # Initialize the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward propagation\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            # Error evaluation\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # Parameter update\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print the averaged loss per minibatch every 100 minibatches\n",
    "            # Compute and print statistics\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if k%100 == 99:\n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, k + 1, running_loss / 100))\n",
    "                running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.301\n",
      "[1,   200] loss: 2.292\n",
      "[1,   300] loss: 2.282\n",
      "[1,   400] loss: 2.264\n",
      "[1,   500] loss: 2.228\n",
      "[1,   600] loss: 2.139\n",
      "[2,   100] loss: 1.833\n",
      "[2,   200] loss: 1.205\n",
      "[2,   300] loss: 0.644\n",
      "[2,   400] loss: 0.442\n",
      "[2,   500] loss: 0.364\n",
      "[2,   600] loss: 0.314\n",
      "[3,   100] loss: 0.273\n",
      "[3,   200] loss: 0.261\n",
      "[3,   300] loss: 0.243\n",
      "[3,   400] loss: 0.228\n",
      "[3,   500] loss: 0.223\n",
      "[3,   600] loss: 0.209\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "backprop_deep(xtrain, ltrain, net, T=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have implemented $backprop\\_deep()$ to complete training the network. <br>\n",
    "The backpropagation occurs for $T$ epochs using mini-batch stochastic gradient descent with momentum. <br>\n",
    "We forward propogate, then we calculate the loss, backpropogate the gradients and finally update the parameters. <br>\n",
    "We evaluate the average loss per $100$ minibatches, and then print it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{3 epochs training}$$\n",
    "We ran the SGD with momentum = $0.9$ and with learning rate = $0.001$ on the training set for $3$ epochs. <br>\n",
    "The loss reduced from $2.301$ after $100$ minibatches of the $1^{st}$ epoch to $0.209$ at the end of $3$ epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yfin = net(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(94.4100)\n"
     ]
    }
   ],
   "source": [
    "_, lpred_fin = yfin.max(1)\n",
    "\n",
    "# calculate the precentage of correctly predicted labels in the test set after training for 3 epochs\n",
    "fin_acc = 100 * (ltest == lpred_fin).float().mean()\n",
    "print(fin_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have re-evaluated the predictions of our trained network on the testing dataset. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{3 epochs training vs. testing}$$\n",
    "We tested the performance of the network parameters trained on the dataset by SGD with momentum using the testing set. <br>\n",
    "Final accuracy on the testing set is $94.4100\\%$. <br>\n",
    "Initial accuracy on the testing set was $11.9200\\%$. <br>\n",
    "Thus, the accuracy of our network in classifying MNIST images of the testing set improved by $82.49\\%$ after training for $3$ epochs on the training set using minibatch Stochastic Gradient Descent with momentum = $0.9$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.6900, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# initialize the net and move it to the GPU\n",
    "net = LeNet().to(device)\n",
    "\n",
    "# Move all the relevant tensors to GPU\n",
    "xtrain = xtrain.to(device)\n",
    "xtest = xtest.to(device)\n",
    "ltrain = ltrain.to(device)\n",
    "ltest = ltest.to(device)\n",
    "\n",
    "# Calculate the initial accuracy percentage of classification of images on the testing set\n",
    "with torch.no_grad():\n",
    "    yinit_gpu = net(xtest)\n",
    "    \n",
    "# Calculate the predictions now.\n",
    "_, lpred_gpu = yinit_gpu.max(1)\n",
    "\n",
    "# calculate the precentage of correctly predicted labels for the initial run on the GPU\n",
    "init_acc_gpu = 100 * (ltest == lpred_gpu).float().mean()\n",
    "print(init_acc_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.301\n",
      "[1,   200] loss: 2.297\n",
      "[1,   300] loss: 2.293\n",
      "[1,   400] loss: 2.287\n",
      "[1,   500] loss: 2.279\n",
      "[1,   600] loss: 2.265\n",
      "[2,   100] loss: 2.237\n",
      "[2,   200] loss: 2.168\n",
      "[2,   300] loss: 1.926\n",
      "[2,   400] loss: 1.345\n",
      "[2,   500] loss: 0.762\n",
      "[2,   600] loss: 0.530\n",
      "[3,   100] loss: 0.419\n",
      "[3,   200] loss: 0.363\n",
      "[3,   300] loss: 0.320\n",
      "[3,   400] loss: 0.297\n",
      "[3,   500] loss: 0.269\n",
      "[3,   600] loss: 0.249\n",
      "[4,   100] loss: 0.220\n",
      "[4,   200] loss: 0.207\n",
      "[4,   300] loss: 0.196\n",
      "[4,   400] loss: 0.191\n",
      "[4,   500] loss: 0.185\n",
      "[4,   600] loss: 0.176\n",
      "[5,   100] loss: 0.161\n",
      "[5,   200] loss: 0.149\n",
      "[5,   300] loss: 0.153\n",
      "[5,   400] loss: 0.148\n",
      "[5,   500] loss: 0.139\n",
      "[5,   600] loss: 0.140\n",
      "[6,   100] loss: 0.125\n",
      "[6,   200] loss: 0.132\n",
      "[6,   300] loss: 0.115\n",
      "[6,   400] loss: 0.117\n",
      "[6,   500] loss: 0.116\n",
      "[6,   600] loss: 0.122\n",
      "[7,   100] loss: 0.115\n",
      "[7,   200] loss: 0.113\n",
      "[7,   300] loss: 0.106\n",
      "[7,   400] loss: 0.101\n",
      "[7,   500] loss: 0.108\n",
      "[7,   600] loss: 0.094\n",
      "[8,   100] loss: 0.094\n",
      "[8,   200] loss: 0.097\n",
      "[8,   300] loss: 0.098\n",
      "[8,   400] loss: 0.096\n",
      "[8,   500] loss: 0.096\n",
      "[8,   600] loss: 0.092\n",
      "[9,   100] loss: 0.095\n",
      "[9,   200] loss: 0.091\n",
      "[9,   300] loss: 0.081\n",
      "[9,   400] loss: 0.079\n",
      "[9,   500] loss: 0.083\n",
      "[9,   600] loss: 0.082\n",
      "[10,   100] loss: 0.080\n",
      "[10,   200] loss: 0.074\n",
      "[10,   300] loss: 0.078\n",
      "[10,   400] loss: 0.084\n",
      "[10,   500] loss: 0.078\n",
      "[10,   600] loss: 0.087\n"
     ]
    }
   ],
   "source": [
    "# Run backprop on this network for 10 epochs\n",
    "backprop_deep(xtrain, ltrain, net, T=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reinitialized a new network and transferred it to the GPU to train. <br>\n",
    "We simply used the $.to(device)$ function to accomplish this task. <br>\n",
    "The accuracy on the testing dataset was calculated initially and displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{3 epochs GPU}$$\n",
    "$3$ epochs on the GPU reduced the loss from $2.303$ initially after $100$ minibatches of $1^{st}$ epoch to $0.277$ <br>\n",
    "$$\\textbf{3 epochs without GPU}$$\n",
    "$3$ epochs without GPU reduced the loss from $2.301$ initially after $100$ minibatches of $1^{st}$ epoch to $0.209$ <br>\n",
    "$$\\textbf{10 epochs GPU}$$\n",
    "$10$ epochs on the GPU reduced the loss from $2.301$ initially after $100$ minibatches of $1^{st}$ epoch to $0.087$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(98.1700, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yfin_gpu = net(xtest)\n",
    "    \n",
    "_, lpred_fin_gpu = yfin_gpu.max(1)\n",
    "\n",
    "# calculate the precentage of correctly predicted labels in the test set after training for 3 epochs on GPU\n",
    "fin_acc_gpu = 100 * (ltest == lpred_fin_gpu).float().mean()\n",
    "print(fin_acc_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have re-evaluated the predictions of our network trained on the GPU on the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{3 epochs GPU - Test vs. Train}$$\n",
    "We tested the performance of the network parameters that were trained for $3$ epochs on the GPU and we got an accuracy percentage of $92.7000\\%$ on this test set. <br>\n",
    "Training loss after $3$ epochs on the GPU was: $0.277$. <br>\n",
    "\n",
    "$$ \\textbf{3 epochs without GPU vs. 3 epochs with GPU} $$\n",
    "Testing accuracy percentage after training without GPU for $3$ epochs was : $94.4100\\%$<br>\n",
    "\n",
    "$$ \\textbf{10 epochs GPU - Test vs. Train} $$\n",
    "We tested the performance of the network parameters that were trained for $10$ epochs on the GPU and we got an accuracy percentage of $98.1700\\%$ on this test set. <br>\n",
    "Training loss after $10$ epochs was: $0.087$. <br>\n",
    "$$\\textbf{10 epochs GPU vs 3 epochs with and without GPU}$$\n",
    "Compared to $3$ epochs on the GPU, our training accuracy using $10$ epochs on GPU improved by $5.47\\%$ from $92.7000\\%$ to $98.1700\\%$. <br>\n",
    "Compared to $3$ epochs without GPU, our training accuracy using $10$ epochs on GPU improved by $3.76\\%$ from $94.4100\\%$ to $98.1700\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "After training for $3$ epochs without GPU, our network had a training loss of $0.209$. <br>\n",
    "Training the network parameters with GPU for $3$ epochs, the training loss was $0.277$. <br>\n",
    "After training for $3$ epochs without GPU, our network had accuracy percentage as $94.4100\\%$ on the testing set. <br>\n",
    "After training for $3$ epochs with GPU, our network had accuracy percentage as $92.7000\\%$ on the testing set. <br>\n",
    "Training the network parameters with GPU for $10$ epochs, the training loss was $0.087$. <br>\n",
    "After training for $10$ epochs with GPU, our network had accuracy percentage as $98.1700\\%$ on the testing set. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferences\n",
    "Comparing the performance of the network using GPU vs. not using it, we conclude that training using GPU does $\\textbf{not}$ have any significant increase in performance in terms of loss or accuracy for training on the same number of epochs without GPU. <br>\n",
    "However, we find that the training the network on the GPU is significantly faster than training the network without a GPU. <br>\n",
    "This would hence allow us to increase the number of epochs that we would be able to run a network, and thus increase the overall performance of our methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have learnt about Convolutional Neural Networks, and implemented LeNet in PyTorch to classify MNIST handwritten images. We trained the whole network without GPU, as well as trained it using GPU and compared their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{Assignment completed by:-} \\\\\n",
    "    \\text{Name: Anirudh Swaminathan } \\\\\n",
    "    \\text{PID: A53316083 } \\\\\n",
    "    \\text{Email ID: aswamina@eng.ucsd.edu}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
